{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較一下範例檔案中的「File I/O」與「xmltodict」讀出來的內容有什麼差異\n",
    "開起xml的三種方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "\n",
      "<CUPOY>\n",
      "\n",
      "    <Title>爬蟲馬拉松</Title>\n",
      "\n",
      "    <Author>Wei</Author>\n",
      "\n",
      "    <Chapters>\n",
      "\n",
      "        <Chapter name=\"01\">資料來源與存取</Chapter>\n",
      "\n",
      "        <Chapter name=\"02\">靜態網頁爬蟲</Chapter>\n",
      "\n",
      "        <Chapter name=\"03\">動態網頁爬蟲</Chapter>\n",
      "\n",
      "    </Chapters>\n",
      "\n",
      "</CUPOY>\n"
     ]
    }
   ],
   "source": [
    "#file I/O\n",
    "data = 'E:\\GitHub\\PyCrawlerMarathon\\homework\\Day003\\sample.xml'\n",
    "with open(data,'r',encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬蟲馬拉松\n",
      "01 資料來源與存取\n",
      "02 靜態網頁爬蟲\n",
      "03 動態網頁爬蟲\n"
     ]
    }
   ],
   "source": [
    "#xml.dom\n",
    "import xml.dom.minidom\n",
    "\n",
    "doc = xml.dom.minidom.parse('E:\\GitHub\\PyCrawlerMarathon\\homework\\Day003\\sample.xml')\n",
    "\n",
    "print(doc.getElementsByTagName('Title')[0].firstChild.nodeValue)\n",
    "\n",
    "chapters = doc.getElementsByTagName('Chapter')\n",
    "for chapter in chapters:\n",
    "    print(chapter.getAttribute('name'),chapter.firstChild.nodeValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬蟲馬拉松\n",
      "01 資料來源與存取\n",
      "02 靜態網頁爬蟲\n",
      "03 動態網頁爬蟲\n"
     ]
    }
   ],
   "source": [
    "#xml.etree\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('E:\\GitHub\\PyCrawlerMarathon\\homework\\Day003\\sample.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "print(root[0].text)\n",
    "chapters = root[2]\n",
    "for chapter in chapters:\n",
    "    print(chapter.attrib['name'],chapter.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬蟲馬拉松\n",
      "01 資料來源與存取\n",
      "02 靜態網頁爬蟲\n",
      "03 動態網頁爬蟲\n"
     ]
    }
   ],
   "source": [
    "#xmltodict\n",
    "import xmltodict\n",
    "\n",
    "with open('E:\\GitHub\\PyCrawlerMarathon\\homework\\Day003\\sample.xml',encoding=\"utf-8\") as fd:\n",
    "    doc = dict(xmltodict.parse(fd.read()))\n",
    "\n",
    "print(doc['CUPOY']['Title'])\n",
    "chapters = doc['CUPOY']['Chapters']['Chapter']\n",
    "for i in chapters:\n",
    "    print(i['@name'],i['#text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據範例檔案的結果：\n",
    "\n",
    "* 1. 請問高雄市有多少地區有溫度資料？\n",
    "\n",
    "* 2. 請取出每一個地區所記錄的第一個時間點跟溫度\n",
    "\n",
    "* 3. 請取出第一個地區所記錄的每一個時間點跟溫度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
