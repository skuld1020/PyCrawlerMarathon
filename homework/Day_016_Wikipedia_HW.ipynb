{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia爬蟲練習\n",
    "* 練習從Wikipedia中爬取文章。先定義一個搜尋的關鍵字，擷取該關鍵字詞的文章。\n",
    "* 目標網址：https://zh.wikipedia.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先定義一個我們想搜尋的字詞，並將它轉換成UTF-8編碼後的URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str( ) & repr( )\n",
    "str()  給人閱讀的 <br>\n",
    "repr()  給機器閱讀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello,world!\n",
      "\n",
      "----\n",
      "hello,world!\n",
      "\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello,world!\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'hello,world!\\n'\n",
    "\n",
    "print(a)          #對a經過加工後輸出，將轉義字元進行轉義\n",
    "print('----')\n",
    "print(str(a))     #可以看到對str返回的值進行print處理，這將與直接print（a）得到相同的結果\n",
    "print('----') \n",
    "a                 #a原來模樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello,world!\\n'\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'hello,world!\\\\n'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(repr(a))    #對於repr返回的值進行print處理，可以看到這與直接在終端輸入a，得到的是相同的結果\n",
    "print('----')\n",
    "repr(a)           #獲得一種機器閱讀的形式，也就是這個變數背地裡是什麼樣子的。(比a多了雙引號)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wiki/%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2\n"
     ]
    }
   ],
   "source": [
    "input_keyword ='網路爬蟲'\n",
    "\n",
    "utf8_url = repr(input_keyword.encode('utf-8')).upper()  #編碼成utf-8並轉為大寫\n",
    "utf8_url = utf8_url.replace('\\\\X','%') #用 % 取代 \\X 得到結果為B'%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2'\n",
    "\n",
    "#要取中間引號內容\n",
    "utf8_url = utf8_url[2:-1:1] #[start:end(不含):step(step=1可寫可不寫)] [2:-1]也行\n",
    "\n",
    "#https://zh.wikipedia.org/wiki/搜尋內容之轉碼\n",
    "root_keyword_link = '/wiki/' + utf8_url\n",
    "print(root_keyword_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例1：送出關鍵字請求後，爬取該關鍵字的文章內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p><b>網路爬蟲</b>（英語：<span lang=\"en\">web crawler</span>），也叫<b>網路蜘蛛</b>（<span lang=\"en\">spider</span>），是一種用來自動瀏覽<a href=\"/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91\" title=\"全球資訊網\">全球資訊網</a>的<a href=\"/wiki/%E7%BD%91%E7%BB%9C%E6%9C%BA%E5%99%A8%E4%BA%BA\" title=\"網路機器人\">網路機器人</a>。其目的一般為編纂<span class=\"ilh-all\" data-foreign-title=\"Web indexing\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"网络索引\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=%E7%BD%91%E7%BB%9C%E7%B4%A2%E5%BC%95&amp;action=edit&amp;redlink=1\" title=\"網路索引（頁面不存在）\">網路索引</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/Web_indexing\" title=\"en:Web indexing\"><span dir=\"auto\" lang=\"en\">Web indexing</span></a></span>）</span></span>。\n",
       " </p>,\n",
       " <p><a href=\"/wiki/%E7%BD%91%E7%BB%9C%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E\" title=\"網路搜尋引擎\">網路</a><a href=\"/wiki/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E\" title=\"搜尋引擎\">搜尋引擎</a>等站點通過爬蟲軟體更新自身的<span class=\"ilh-all\" data-foreign-title=\"Web content\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"網站內容\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=%E7%B6%B2%E7%AB%99%E5%85%A7%E5%AE%B9&amp;action=edit&amp;redlink=1\" title=\"網站內容（頁面不存在）\">網站內容</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/Web_content\" title=\"en:Web content\"><span dir=\"auto\" lang=\"en\">Web content</span></a></span>）</span></span>或其對其他網站的索引。網路爬蟲可以將自己所存取的頁面儲存下來，以便搜尋引擎事後生成<span class=\"ilh-all\" data-foreign-title=\"Index (search engine)\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"索引 (搜索引擎)\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=%E7%B4%A2%E5%BC%95_(%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E)&amp;action=edit&amp;redlink=1\" title=\"索引 (搜尋引擎)（頁面不存在）\">索引</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/Index_(search_engine)\" title=\"en:Index (search engine)\"><span dir=\"auto\" lang=\"en\">Index (search engine)</span></a></span>）</span></span>供用戶搜尋。\n",
       " </p>,\n",
       " <p>爬蟲存取網站的過程會消耗目標系統資源。不少網路系統並不默許爬蟲工作。因此在存取大量頁面時，爬蟲需要考慮到規劃、負載，還需要講「禮貌」。 不願意被爬蟲存取、被爬蟲主人知曉的公開站點可以使用<a href=\"/wiki/Robots.txt\" title=\"Robots.txt\">robots.txt</a>檔案之類的方法避免存取。這個檔案可以要求<span class=\"ilh-all\" data-foreign-title=\"Software agent\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"软件助理\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=%E8%BD%AF%E4%BB%B6%E5%8A%A9%E7%90%86&amp;action=edit&amp;redlink=1\" title=\"軟體助理（頁面不存在）\">機器人</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/Software_agent\" title=\"en:Software agent\"><span dir=\"auto\" lang=\"en\">Software agent</span></a></span>）</span></span>只對<a class=\"mw-redirect\" href=\"/wiki/%E7%BD%91%E7%AB%99\" title=\"網站\">網站</a>的一部分進行索引，或完全不作處理。\n",
       " </p>,\n",
       " <p>網際網路上的頁面極多，即使是最大的爬蟲系統也無法做出完整的索引。因此在公元2000年之前的全球資訊網出現初期，搜尋引擎經常找不到多少相關結果。現在的搜尋引擎在這方面已經進步很多，能夠即刻給出高品質結果。\n",
       " </p>,\n",
       " <p>爬蟲還可以驗證<a href=\"/wiki/%E8%B6%85%E9%80%A3%E7%B5%90\" title=\"超連結\">超連結</a>和<a href=\"/wiki/HTML\" title=\"HTML\">HTML</a>代碼，用於<span class=\"ilh-all\" data-foreign-title=\"Web scraping\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"网络抓取\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8F%96&amp;action=edit&amp;redlink=1\" title=\"網路抓取（頁面不存在）\">網路抓取</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/Web_scraping\" title=\"en:Web scraping\"><span dir=\"auto\" lang=\"en\">Web scraping</span></a></span>）</span></span>（參見<a href=\"/wiki/%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%BC%96%E7%A8%8B\" title=\"資料驅動編程\">資料驅動編程</a>）。\n",
       " </p>,\n",
       " <p>網路爬蟲也可稱作網路蜘蛛<sup class=\"reference\" id=\"cite_ref-spekta_1-0\"><a href=\"#cite_note-spekta-1\">[1]</a></sup>、螞蟻、自動索引程式（<span lang=\"en\">automatic indexer</span>）<sup class=\"reference\" id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup> ，或（在<span class=\"ilh-all\" data-foreign-title=\"FOAF (software)\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"FOAF (软件)\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=FOAF_(%E8%BD%AF%E4%BB%B6)&amp;action=edit&amp;redlink=1\" title=\"FOAF (軟體)（頁面不存在）\">FOAF</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/FOAF_(software)\" title=\"en:FOAF (software)\"><span dir=\"auto\" lang=\"en\">FOAF (software)</span></a></span>）</span></span>軟體中）稱為網路疾走（<span lang=\"en\">web scutter</span>）。<sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\">[3]</a></sup></p>,\n",
       " <p>網路爬蟲始於一張被稱作種子的統一資源位址（URL）列表。當網路爬蟲存取這些統一資源定位器時，它們會甄別出頁面上所有的超連結，並將它們寫入一張「待訪列表」，即所謂<span class=\"ilh-all\" data-foreign-title=\"crawl frontier\" data-lang-code=\"en\" data-lang-name=\"英語\" data-orig-title=\"爬行疆域\"><span class=\"ilh-page\"><a class=\"new\" href=\"/w/index.php?title=%E7%88%AC%E8%A1%8C%E7%96%86%E5%9F%9F&amp;action=edit&amp;redlink=1\" title=\"爬行疆域（頁面不存在）\">爬行疆域</a></span><span class=\"noprint ilh-comment\">（<span class=\"ilh-lang\">英語</span><span class=\"ilh-colon\">：</span><span class=\"ilh-link\"><a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/crawl_frontier\" title=\"en:crawl frontier\"><span dir=\"auto\" lang=\"en\">crawl frontier</span></a></span>）</span></span>。此疆域上的URL將會被按照一套策略迴圈來存取。如果爬蟲在執行的過程中複製歸檔和儲存網站上的資訊，這些檔案通常儲存，使他們可以較容易的被檢視。閱讀和瀏覽他們儲存的網站上並即時更新的資訊，這些被儲存的<a href=\"/wiki/%E7%B6%B2%E9%A0%81\" title=\"網頁\">網頁</a>又被稱為「快照」。越大容量的網頁意味著網路爬蟲只能在給予的時間內下載越少部分的網頁，所以要優先考慮其下載。高變化率意味著網頁可能已經被更新或者被取代。一些伺服器端軟體生成的URL（統一資源定位符）也使得網路爬蟲很難避免檢索到重複內容。\n",
       " </p>,\n",
       " <p>但是<a href=\"/wiki/%E4%BA%92%E8%81%94%E7%BD%91\" title=\"網際網路\">網際網路</a>的資源卷帙浩繁，這也意味著網路爬蟲只能在一定時間內下載有限數量的網頁，因此它需要衡量優先順序的下載方式。有時候網頁出現、更新和消失的速度很快，也就是說網路爬蟲下載的網頁在幾秒後就已經被修改或甚至刪除了。這些都是網路爬蟲設計師們所面臨的兩個問題。\n",
       " </p>,\n",
       " <p>再者，<a href=\"/wiki/%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"伺服器\">伺服器</a>端軟體所生成的統一資源位址數量龐大，以至網路爬蟲難免也會採集到重複的內容。根據<a class=\"mw-redirect\" href=\"/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E5%82%B3%E8%BC%B8%E5%8D%94%E5%AE%9A\" title=\"超文字傳輸協定\">超文字傳輸協定</a>，無盡組合的參數所返回的頁面中，只有很少一部分確實傳回正確的內容。例如：數張快照陳列室的網站，可能通過幾個參數，讓用戶選擇相關快照：其一是通過四種方法對快照排序，其二是關於快照解析度的的三種選擇，其三是兩種檔案格式，另加一個用戶可否提供內容的選擇，這樣對於同樣的結果會有48種（4*3*2）不同的統一資源位址與其關聯。這種數學組合替網路爬蟲造成了麻煩，因為它們必須越過這些無關指令碼變化的組合，尋找不重複的內容。\n",
       " </p>,\n",
       " <p>爬蟲的實現由以下策略組成：<sup class=\"reference\" id=\"cite_ref-4\"><a href=\"#cite_note-4\">[4]</a></sup></p>,\n",
       " <p>爬蟲可能只想搜尋HTML頁面而避免其他MIME 類型。為了只請求HTML資源，爬蟲在抓取整個以GET方式請求的資源之前，通過建立HTTP的HEAD請求來決定網路資源的MIME類型。為了避免發出過多的請求，爬蟲會檢查URL和只請求那些以某些字元（如.html, .htm, .asp, .aspx, .php, .jsp, .jspx 或 / ）作為字尾的URL。這個策略可能會跳過很多HTML網路資源。\n",
       " </p>,\n",
       " <p>有些爬蟲還能避免請求一些帶有「?」的資源（動態生成）。為了避免掉入從網站下載無限量的URL的爬蟲陷阱。不過假若網站重寫URL以簡化URL的目的，這個策略就變得不可靠了。\n",
       " </p>,\n",
       " <p>爬蟲通常使用某些URL規格化的方式以避免資源的重複爬取。URL規格化，指的是以某種一致的方式修改和標準化URL的過程。這個過程有各種各樣的處理規則，包括統一轉換為小寫、移除「.」和「..」片段，以及在非空路徑里插入斜杆。\n",
       " </p>,\n",
       " <p>有些爬蟲希望從指定的網站中儘可能地爬取資源。而路徑上移爬蟲就是為了能爬取每個URL里提示出的每個路徑。<sup class=\"reference\" id=\"cite_ref-5\"><a href=\"#cite_note-5\">[5]</a></sup> 例如，給定一個Http的種子URL: http://llama.org/hamster/monkey/page.html ，要爬取 /hamster/monkey/ ， /hamster/ 和 / 。Cothey發現路徑能非常有效地爬取獨立的資源，或以某種規律無法在站內部連結接爬取到的資源。\n",
       " </p>,\n",
       " <p>對於爬蟲來說，一個頁面的重要性也可以說是，給定查詢條件一個頁面相似效能起到的作用。網路爬蟲要下載相似的網頁被稱為主題爬蟲或局部爬蟲。這個主題爬蟲或局部爬蟲的概念第一次被<a class=\"new\" href=\"/w/index.php?title=Filippo_Menczer&amp;action=edit&amp;redlink=1\" title=\"Filippo Menczer（頁面不存在）\">Filippo Menczer</a><sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup><sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\">[7]</a></sup> 和  Soumen Chakrabarti <i>等人提出的。</i><sup class=\"reference\" id=\"cite_ref-8\"><a href=\"#cite_note-8\">[8]</a></sup></p>,\n",
       " <p>網站的屬性之一就是經常動態變化，而爬取網站的一小部分往往需要花費幾個星期或者幾個月。等到網站爬蟲完成它的爬取，很多事件也已經發生了，包括增加、更新和刪除。\n",
       " 在搜尋引擎的角度，因為沒有檢測這些變化，會導致儲存了過期資源的代價。最常用的估價函式是新鮮度和過時性。\n",
       " 新鮮度：這是一個衡量抓取內容是不是準確的二元值。在時間t內，倉庫中頁面p的新鮮度是這樣定義的：\n",
       " </p>,\n",
       " <p>過時性:這是一個衡量本地已抓取的內容過時程度的指標。在時間t時，倉庫中頁面p的時效性的定義如下：\n",
       " </p>,\n",
       " <p>爬蟲相比於人，可以有更快的檢索速度和更深的層次，所以，他們可能使一個站點癱瘓。不需要說一個單獨的爬蟲一秒鐘要執行多條請求，下載大的檔案。一個伺服器也會很難回應多執行緒爬蟲的請求。\n",
       " 就像Koster所注意的那樣，爬蟲的使用對很多工作都是很有用的，但是對一般的社區，也需要付出代價。使用爬蟲的代價包括：<sup class=\"reference\" id=\"cite_ref-coffman_9-0\"><a href=\"#cite_note-coffman-9\">[9]</a></sup></p>,\n",
       " <p>對這些問題的局部解決方法是漫遊器排除協定（Robots exclusion protocol），也被稱為robots.txt議定書<sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup>，這份協定是讓管理員指明網路伺服器的不應該爬取的約定。這個標準沒有包括重新存取一台伺服器的間隔的建議，雖然設定存取間隔是避免伺服器超載的最有效辦法。最近的商業搜尋引擎，如Google，Ask Jeeves，MSN和Yahoo可以在robots.txt中使用一個額外的 「Crawl-delay」參數來指明請求之間的延遲。\n",
       " </p>,\n",
       " <p>一個並列爬蟲是並列執行多個行程的爬蟲。它的目標是最大化下載的速度，同時儘量減少並列的開銷和下載重複的頁面。為了避免下載一個頁面兩次，爬蟲系統需要策略來處理爬蟲執行時新發現的URL，因為同一個URL位址，可能被不同的爬蟲行程抓到。\n",
       " </p>,\n",
       " <p><br/></p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'authority': 'zh.wikipedia.org',\n",
    "           'method': 'GET',\n",
    "           'path': '/wiki/' + root_keyword_link,\n",
    "           'scheme': 'https',\n",
    "           'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "           'accept-encoding': 'gzip, deflate, br',\n",
    "           'accept-language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "           'cache-control': 'max-age=0',\n",
    "           'cookie': 'TBLkisOn=0; WMF-Last-Access-Global=03-Jul-2020; GeoIP=TW:TPE:Taipei:25.05:121.53:v4; WMF-Last-Access=03-Jul-2020; zhwikimwuser-sessionId=91d26214fb90c309625c',\n",
    "           'referer': 'https://zh.wikipedia.org/wiki/Wikipedia:%E9%A6%96%E9%A1%B5',\n",
    "           'sec-fetch-dest': 'document',\n",
    "           'sec-fetch-mode': 'navigate',\n",
    "           'sec-fetch-site': 'none',\n",
    "           'sec-fetch-user': '?1',\n",
    "           'upgrade-insecure-requests': '1',\n",
    "           'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Mobile Safari/537.36'}\n",
    "\n",
    "url = 'https://zh.wikipedia.org' + root_keyword_link  # 組合關鍵字查詢URL\n",
    "resp = requests.get(url, headers=headers)\n",
    "resp.encoding = 'utf-8'\n",
    "html = BeautifulSoup(resp.text, \"lxml\")\n",
    "content = html.find('div',attrs = {'id':'mw-content-text'}).find_all('p')\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "網路爬蟲（英語：web crawler），也叫網路蜘蛛（spider），是一種用來自動瀏覽全球資訊網的網路機器人。其目的一般為編纂網路索引（英語：Web indexing）。\n",
      "\n",
      "網路搜尋引擎等站點通過爬蟲軟體更新自身的網站內容（英語：Web content）或其對其他網站的索引。網路爬蟲可以將自己所存取的頁面儲存下來，以便搜尋引擎事後生成索引（英語：Index (search engine)）供用戶搜尋。\n",
      "\n",
      "爬蟲存取網站的過程會消耗目標系統資源。不少網路系統並不默許爬蟲工作。因此在存取大量頁面時，爬蟲需要考慮到規劃、負載，還需要講「禮貌」。 不願意被爬蟲存取、被爬蟲主人知曉的公開站點可以使用robots.txt檔案之類的方法避免存取。這個檔案可以要求機器人（英語：Software agent）只對網站的一部分進行索引，或完全不作處理。\n",
      "\n",
      "網際網路上的頁面極多，即使是最大的爬蟲系統也無法做出完整的索引。因此在公元2000年之前的全球資訊網出現初期，搜尋引擎經常找不到多少相關結果。現在的搜尋引擎在這方面已經進步很多，能夠即刻給出高品質結果。\n",
      "\n",
      "爬蟲還可以驗證超連結和HTML代碼，用於網路抓取（英語：Web scraping）（參見資料驅動編程）。\n",
      "\n",
      "網路爬蟲也可稱作網路蜘蛛[1]、螞蟻、自動索引程式（automatic indexer）[2] ，或（在FOAF（英語：FOAF (software)）軟體中）稱為網路疾走（web scutter）。[3]\n",
      "網路爬蟲始於一張被稱作種子的統一資源位址（URL）列表。當網路爬蟲存取這些統一資源定位器時，它們會甄別出頁面上所有的超連結，並將它們寫入一張「待訪列表」，即所謂爬行疆域（英語：crawl frontier）。此疆域上的URL將會被按照一套策略迴圈來存取。如果爬蟲在執行的過程中複製歸檔和儲存網站上的資訊，這些檔案通常儲存，使他們可以較容易的被檢視。閱讀和瀏覽他們儲存的網站上並即時更新的資訊，這些被儲存的網頁又被稱為「快照」。越大容量的網頁意味著網路爬蟲只能在給予的時間內下載越少部分的網頁，所以要優先考慮其下載。高變化率意味著網頁可能已經被更新或者被取代。一些伺服器端軟體生成的URL（統一資源定位符）也使得網路爬蟲很難避免檢索到重複內容。\n",
      "\n",
      "但是網際網路的資源卷帙浩繁，這也意味著網路爬蟲只能在一定時間內下載有限數量的網頁，因此它需要衡量優先順序的下載方式。有時候網頁出現、更新和消失的速度很快，也就是說網路爬蟲下載的網頁在幾秒後就已經被修改或甚至刪除了。這些都是網路爬蟲設計師們所面臨的兩個問題。\n",
      "\n",
      "再者，伺服器端軟體所生成的統一資源位址數量龐大，以至網路爬蟲難免也會採集到重複的內容。根據超文字傳輸協定，無盡組合的參數所返回的頁面中，只有很少一部分確實傳回正確的內容。例如：數張快照陳列室的網站，可能通過幾個參數，讓用戶選擇相關快照：其一是通過四種方法對快照排序，其二是關於快照解析度的的三種選擇，其三是兩種檔案格式，另加一個用戶可否提供內容的選擇，這樣對於同樣的結果會有48種（4*3*2）不同的統一資源位址與其關聯。這種數學組合替網路爬蟲造成了麻煩，因為它們必須越過這些無關指令碼變化的組合，尋找不重複的內容。\n",
      "\n",
      "爬蟲的實現由以下策略組成：[4]\n",
      "爬蟲可能只想搜尋HTML頁面而避免其他MIME 類型。為了只請求HTML資源，爬蟲在抓取整個以GET方式請求的資源之前，通過建立HTTP的HEAD請求來決定網路資源的MIME類型。為了避免發出過多的請求，爬蟲會檢查URL和只請求那些以某些字元（如.html, .htm, .asp, .aspx, .php, .jsp, .jspx 或 / ）作為字尾的URL。這個策略可能會跳過很多HTML網路資源。\n",
      "\n",
      "有些爬蟲還能避免請求一些帶有「?」的資源（動態生成）。為了避免掉入從網站下載無限量的URL的爬蟲陷阱。不過假若網站重寫URL以簡化URL的目的，這個策略就變得不可靠了。\n",
      "\n",
      "爬蟲通常使用某些URL規格化的方式以避免資源的重複爬取。URL規格化，指的是以某種一致的方式修改和標準化URL的過程。這個過程有各種各樣的處理規則，包括統一轉換為小寫、移除「.」和「..」片段，以及在非空路徑里插入斜杆。\n",
      "\n",
      "有些爬蟲希望從指定的網站中儘可能地爬取資源。而路徑上移爬蟲就是為了能爬取每個URL里提示出的每個路徑。[5] 例如，給定一個Http的種子URL: http://llama.org/hamster/monkey/page.html ，要爬取 /hamster/monkey/ ， /hamster/ 和 / 。Cothey發現路徑能非常有效地爬取獨立的資源，或以某種規律無法在站內部連結接爬取到的資源。\n",
      "\n",
      "對於爬蟲來說，一個頁面的重要性也可以說是，給定查詢條件一個頁面相似效能起到的作用。網路爬蟲要下載相似的網頁被稱為主題爬蟲或局部爬蟲。這個主題爬蟲或局部爬蟲的概念第一次被Filippo Menczer[6][7] 和  Soumen Chakrabarti 等人提出的。[8]\n",
      "網站的屬性之一就是經常動態變化，而爬取網站的一小部分往往需要花費幾個星期或者幾個月。等到網站爬蟲完成它的爬取，很多事件也已經發生了，包括增加、更新和刪除。\n",
      "在搜尋引擎的角度，因為沒有檢測這些變化，會導致儲存了過期資源的代價。最常用的估價函式是新鮮度和過時性。\n",
      "新鮮度：這是一個衡量抓取內容是不是準確的二元值。在時間t內，倉庫中頁面p的新鮮度是這樣定義的：\n",
      "\n",
      "過時性:這是一個衡量本地已抓取的內容過時程度的指標。在時間t時，倉庫中頁面p的時效性的定義如下：\n",
      "\n",
      "爬蟲相比於人，可以有更快的檢索速度和更深的層次，所以，他們可能使一個站點癱瘓。不需要說一個單獨的爬蟲一秒鐘要執行多條請求，下載大的檔案。一個伺服器也會很難回應多執行緒爬蟲的請求。\n",
      "就像Koster所注意的那樣，爬蟲的使用對很多工作都是很有用的，但是對一般的社區，也需要付出代價。使用爬蟲的代價包括：[9]\n",
      "對這些問題的局部解決方法是漫遊器排除協定（Robots exclusion protocol），也被稱為robots.txt議定書[10]，這份協定是讓管理員指明網路伺服器的不應該爬取的約定。這個標準沒有包括重新存取一台伺服器的間隔的建議，雖然設定存取間隔是避免伺服器超載的最有效辦法。最近的商業搜尋引擎，如Google，Ask Jeeves，MSN和Yahoo可以在robots.txt中使用一個額外的 「Crawl-delay」參數來指明請求之間的延遲。\n",
      "\n",
      "一個並列爬蟲是並列執行多個行程的爬蟲。它的目標是最大化下載的速度，同時儘量減少並列的開銷和下載重複的頁面。為了避免下載一個頁面兩次，爬蟲系統需要策略來處理爬蟲執行時新發現的URL，因為同一個URL位址，可能被不同的爬蟲行程抓到。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in content:\n",
    "    print(p.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例2：從爬取的文章內容中，擷取出有外部連結的關鍵字。這些關鍵字在文章中是以藍色字體顯示，會連到外部的網頁，並解釋其內容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全球資訊網\n",
      "https://zh.wikipedia.org/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91\n",
      "網路機器人\n",
      "https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E6%9C%BA%E5%99%A8%E4%BA%BA\n",
      "網路\n",
      "https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E\n",
      "搜尋引擎\n",
      "https://zh.wikipedia.org/wiki/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E\n",
      "robots.txt\n",
      "https://zh.wikipedia.org/wiki/Robots.txt\n",
      "網站\n",
      "https://zh.wikipedia.org/wiki/%E7%BD%91%E7%AB%99\n",
      "超連結\n",
      "https://zh.wikipedia.org/wiki/%E8%B6%85%E9%80%A3%E7%B5%90\n",
      "HTML\n",
      "https://zh.wikipedia.org/wiki/HTML\n",
      "資料驅動編程\n",
      "https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%BC%96%E7%A8%8B\n",
      "網頁\n",
      "https://zh.wikipedia.org/wiki/%E7%B6%B2%E9%A0%81\n",
      "網際網路\n",
      "https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91\n",
      "伺服器\n",
      "https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E5%99%A8\n",
      "超文字傳輸協定\n",
      "https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E5%82%B3%E8%BC%B8%E5%8D%94%E5%AE%9A\n"
     ]
    }
   ],
   "source": [
    "for a in content:\n",
    "    a_tag = a.find_all('a',href=re.compile('^(/wiki/)(.+\\S)$'))  #有些找不到會返回空值\n",
    "    if len(a_tag)>0:\n",
    "        for i in a_tag:\n",
    "            link_id = i.get('href')\n",
    "            link = 'https://zh.wikipedia.org' + link_id\n",
    "            print(i.text)\n",
    "            print(link)     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業：接下來定義一個爬蟲函數，這個函數的主要工作為：\n",
    "(1) 爬取當前關鍵字的解釋，並存入檔案(因為文章內容太多會佔滿整個頁面，所以存成檔案，方便後續檢視)<br>\n",
    "(2) 萃取出當前關鍵字所引用的外部連結，當作新的查詢關鍵字<br>\n",
    "(3) 把第(2)擷取到的關鍵字當作新的關鍵字，回到第(1)步，爬取新的關鍵字解釋。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義一個利用關鍵字轉換成維基網址\n",
    "def get_url(word):\n",
    "    utf8_url = repr(word.encode('utf-8')).upper()  #編碼成utf-8並轉為大寫\n",
    "    utf8_url = utf8_url.replace('\\\\X','%') #用 % 取代 \\X 得到結果為B'%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2'\n",
    "\n",
    "    #要取中間引號內容\n",
    "    utf8_url = utf8_url[2:-1:1] #[start:end(不含):step(step=1可寫可不寫)] [2:-1]也行\n",
    "\n",
    "    #https://zh.wikipedia.org/wiki/搜尋內容之轉碼\n",
    "    root_keyword_link = '/wiki/' + utf8_url\n",
    "    return 'https://zh.wikipedia.org' + root_keyword_link\n",
    "\n",
    "#爬取維基頁面的主要內容\n",
    "def get_content(url):\n",
    "    headers = {'authority': 'zh.wikipedia.org',\n",
    "           'method': 'GET',\n",
    "           'path': '/wiki/' + root_keyword_link,\n",
    "           'scheme': 'https',\n",
    "           'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "           'accept-encoding': 'gzip, deflate, br',\n",
    "           'accept-language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "           'cache-control': 'max-age=0',\n",
    "           'cookie': 'TBLkisOn=0; WMF-Last-Access-Global=03-Jul-2020; GeoIP=TW:TPE:Taipei:25.05:121.53:v4; WMF-Last-Access=03-Jul-2020; zhwikimwuser-sessionId=91d26214fb90c309625c',\n",
    "           'referer': 'https://zh.wikipedia.org/wiki/Wikipedia:%E9%A6%96%E9%A1%B5',\n",
    "           'sec-fetch-dest': 'document',\n",
    "           'sec-fetch-mode': 'navigate',\n",
    "           'sec-fetch-site': 'none',\n",
    "           'sec-fetch-user': '?1',\n",
    "           'upgrade-insecure-requests': '1',\n",
    "           'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Mobile Safari/537.36'}\n",
    "\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.encoding = 'utf-8'\n",
    "    html = BeautifulSoup(resp.text, \"lxml\")\n",
    "    content = html.find('div',attrs = {'id':'mw-content-text'}).find_all('p')\n",
    "    for p in content:\n",
    "        print(p.get_text())\n",
    "    \n",
    "def get_keyword(url):\n",
    "    headers = {'authority': 'zh.wikipedia.org',\n",
    "           'method': 'GET',\n",
    "           'path': '/wiki/' + root_keyword_link,\n",
    "           'scheme': 'https',\n",
    "           'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "           'accept-encoding': 'gzip, deflate, br',\n",
    "           'accept-language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "           'cache-control': 'max-age=0',\n",
    "           'cookie': 'TBLkisOn=0; WMF-Last-Access-Global=03-Jul-2020; GeoIP=TW:TPE:Taipei:25.05:121.53:v4; WMF-Last-Access=03-Jul-2020; zhwikimwuser-sessionId=91d26214fb90c309625c',\n",
    "           'referer': 'https://zh.wikipedia.org/wiki/Wikipedia:%E9%A6%96%E9%A1%B5',\n",
    "           'sec-fetch-dest': 'document',\n",
    "           'sec-fetch-mode': 'navigate',\n",
    "           'sec-fetch-site': 'none',\n",
    "           'sec-fetch-user': '?1',\n",
    "           'upgrade-insecure-requests': '1',\n",
    "           'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Mobile Safari/537.36'}\n",
    "\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.encoding = 'utf-8'\n",
    "    html = BeautifulSoup(resp.text, \"lxml\")\n",
    "    content = html.find('div',attrs = {'id':'mw-content-text'}).find_all('p')\n",
    "    linklist=list()\n",
    "    for a in content:\n",
    "        a_tag = a.find_all('a',href=re.compile('^(/wiki/)(.+\\S)$'))  #有些找不到會返回空值\n",
    "        if len(a_tag)>0:\n",
    "            for i in a_tag:\n",
    "                link_id = i.get('href')\n",
    "                link = 'https://zh.wikipedia.org' + link_id\n",
    "                linklist.append(link)\n",
    "            return linklist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明信片，一種專供書寫文字，不必封函，即可交郵局寄遞的郵件。其正面為信封的格式，反面具有信箋的作用。優點是省貼郵票和不用信封，缺點是篇幅小而無隱密性。亦稱為「郵片」。明信片所寫的內容公開，可被他人所看見，內容通常不涉及隱私權之虞，故稱為明信。在某些地方明信片郵資較普通信函資費便宜。依據台灣中華郵政業務說明[1]，一般民眾可自行印製明信片但不得標誌「中華民國郵政」，而中國大陸的中國郵政亦有類似規定，因此許多人會稱郵局發行之明信片為「郵政明信片」（postal card，帶郵資符），而民間印製者則以泛稱之「明信片」（postcard）指稱。\n",
      "\n",
      "一般在卡片的反面印有圖案（風景、繪畫、宣傳漫畫等等），在正面可以貼郵票，寫收件人地址和郵件內容。有的明信片上已經印好郵票，稱作郵資明信片。\n",
      "\n",
      "美國費城約翰·P·卡爾頓，在1861年將明信片的專利售予H·L·利普曼。利普曼製作了鑲有邊框的明信片，並加上「利普曼郵政卡片」（Lipman's postal card）的標誌。歐洲在九年後也開始製作明信片。但是第一個使用明信片的國家，則是1876年的鄂圖曼土耳其。\n",
      "\n",
      "美國郵局在1873年開始發行帶有郵資的郵政明信片。郵局為了因應人們想找一些更方便的方法來寄送一些便籤而製作了這些明信片，而且也只有郵局可以印製。直到1898年5月19日美國國會通過了私人郵寄卡片法案，才准許私人出版商和印刷廠製作明信片。不過最初美國政府並不允許私人企業稱自行印製的卡片為「明信片」，所以他們只好稱為「紀念品卡」（souvenir cards）。雖然這個禁令到1901年被撤銷，但直到1908年人們才被准許將地址寫在卡片的側欄。\n",
      "\n",
      "美國的第一張明信片是1893年創造出來，用來宣傳芝加哥的哥倫布紀念博覽會。此後美國政府就政府透過郵政部的規範，准許印刷商發行1分明信片（1便士明信片）。\n",
      "\n",
      "世界上第一張明信片是1869年在奧地利發行的一張印有郵票的明信片。在1870年和1871年的普法戰爭中明信片作為戰地信件獲得青睞和普及。\n",
      "\n",
      "在台灣是日本統治台灣十年後才通用的郵遞形式，故年紀較大的人們會用繪葉書（エハガキ）來稱呼。\n",
      "\n",
      "集郵中，有一種類型便是收集明信片，並有對應之明信片學。目前在全世界範圍內也有一群人進行「明信片」為主的交流，如Postcrossing。\n",
      "\n",
      "郵局是郵政系統中的基本設施。\n",
      "\n",
      "郵局負責郵件的投寄、收件、分類、處理、傳送及交付。郵局亦會提供其他郵政相關的服務，例如郵政信箱、郵資及包裝供應。另外，一些郵局亦會提供非郵政服務，如處理護照及其他政府表格的申請、匯票，以及銀行、保險等金融服務。\n",
      "\n",
      "對於不想在家中或辦公室收件的人，或居住地點偏僻而無法使用郵政服務的人，郵局會對他們借出郵政信箱（設於郵局內），令他們可在郵局中收件。\n",
      "\n",
      "郵局的內房會用作處理郵件的分類及交付。郵件亦會被一些不對公眾開放的郵局（沒有服務櫃檯的郵件處理中心）去處理。\n",
      "\n",
      "中華郵政是中華民國唯一的郵政事業機構，為中華民國交通部完全持股的國營企業，在國內經常逕稱為郵局。其業務除郵遞相關領域外，亦涵蓋儲匯、人身保險等簡易金融服務[4]。其前身為交通部郵政總局，為突破既有的經營限制、並增加市場競爭力，2002年7月中華民國政府修正《郵政法》，並於2003年1月1日將其公司化（英語：Corporatization）改為現制。其標章由篆體的「郵」字構成。\n",
      "\n",
      "公路總局民用航空局高速公路局航港局鐵道局\n",
      "臺灣鐵路管理局中華郵政公司臺灣港務公司桃園國際機場公司\n",
      "\n",
      "國道省道縣道 - 市道（列表）鄉道 - 區道專用公路編號與名稱對照表\n",
      "\n",
      "高速公路快速道路\n",
      "\n",
      "市區道路農路 - 林道產業道路 - 軍用道路\n",
      "\n",
      "汽車客運（業者）計程車車輛號牌公共自行車\n",
      "（台北 - 高雄 - 新北）\n",
      "\n",
      "台鐵：西部幹線 - 東部幹線 - 南迴線路線列表 - 車站列表台灣高速鐵路\n",
      "\n",
      "捷運路線列表台鐵捷運化輕軌捷運系統\n",
      "\n",
      "林鐵 - 糖鐵 - 鹽鐵 - 礦鐵\n",
      "\n",
      "港口（漁港列表）渡輪航運業者\n",
      "\n",
      "機場航空業者\n",
      "\n",
      "台灣郵政發展台灣地區郵遞區號台灣電信業者列表台灣長途電話區號表台灣網際網路發展\n",
      "\n",
      "台灣古道清代台灣鐵路清代台灣郵政縱貫鐵路縱貫公路北橫公路－中橫公路－南橫公路臺灣鐵路貨物搬運公司臺灣汽車客運公司台灣高速鐵路公司交通部電信總局\n",
      "\n",
      "台灣橋樑台灣隧道台灣管線台灣汽車台灣的電子票證\n",
      "\n",
      "1878年，中國海關總稅務司羅伯特·赫德提議設立官方的近代郵政局；當年，北洋通商大臣李鴻章決定於上海、北京、天津、煙臺和牛莊（今營口）五處試辦郵政業務，並且委託赫德的總稅務司進行管理。翌年，五處郵政辦事處以「海關撥駟達[a]書信館」的名稱開始營業，[5]1880年改「海關拔駟達局」。\n",
      "\n",
      "1896年3月20日，在交由海關部門試辦郵政業務十四年以後，清光緒帝根據總理衙門「興辦郵政」的奏摺，海關試辦之郵政，自此日起正式奉准成為「大清郵政官局」，所有開辦國家郵政事務，仍由總稅務司赫德綜理，於是赫德又兼任「總郵政司」[6]:30。光緒二十三年一月十九日（1897年2月20日），大清郵政開辦，原海關拔駟達局改隸大清郵政；江海關撥駟達局正式更名為「上海大清郵政局」，1899年改「上海郵政總局」。天津海關拔駟達局改「天津大清郵政局」，簡稱「大清郵政津局」。1906年，清政府設立「郵傳部」。1911年，郵傳部接管郵政，郵政從此脫離海關，成為獨立的系統，「總郵政司署」改為郵傳部下的「郵政總局」[6]:41[7]:361；從此，郵政業務正式脫離海關（水師、海軍），實現獨立營運，並使用「大清國郵政」作為郵票銘記[8]。\n",
      "\n",
      "1912年1月1日，中華民國成立，「大清郵政」改名為「中華郵政」[9]:411[10][11][12][13]，並啟用「中華民國郵政」作為早期的郵票銘記[14]，直至1949年改用「中華郵政」為止。同時，郵政總局的建制不變，而改隸新成立之交通部所管轄，但因其一切郵政系統之相關事務仍由外國人繼續主持，故未受北洋政府實際管理或運營。1914年3月1日，中華郵政代表「中華民國」加入萬國郵政聯盟[6]:44。\n",
      "\n",
      "1927年11月1日，國民政府交通部郵政總局於南京成立，並任命時任北京的郵政總局的總辦鐵士蘭為總辦[7]:416；內部先後設有「八處二室一委會」[b]，下轄各區郵政管理局、辦事處等，以管理全國郵政事務為主要職責。\n",
      "\n",
      "1928年，南北兩總局在上海簽訂共管全國郵政條款[6]。1929年6月12日，交通部郵政總局密令鐵士蘭結束北京總局局務，準備南遷；之後國民政府克復北京，交通部郵政總局即裁撤北京總局，人員、文件均南遷，全國郵政統一。[7]:418\n",
      "1932年滿洲國成立後，中華郵政停止在東北的運營而撤到關內。\n",
      "\n",
      "1935年，《郵政法》公布，郵儲總局改制為「郵政儲金匯業局」，隸屬於交通部郵政總局，並同時開辦簡易人壽保險業務。\n",
      "\n",
      "1937年中國抗日戰爭爆發，7月18日，總局命令各局，在各地機關與民眾撤離前，不得撤退[6]:84。雖然日偽當局在淪陷區成立郵政機構，但各地郵政局仍同中華郵政聯絡並由中華郵政供應郵票，重慶政府在國際通郵樞紐上海設郵政總局上海辦事處，代表重慶指導上海、江蘇、浙江、安徽郵政運作。1938年期日本佔領當局和傀儡政府逐漸開始控制郵政，但一些地區郵政機構維持與重慶的聯絡達5-6年之久，例如上海郵政局直到1943年才被日偽控制。雖受日偽干預控制，淪陷區郵政機構仍通過密函渠道繼續與重慶在重大事務方面保持聯絡。\n",
      "\n",
      "抗戰勝利後，中華郵政總局於1945年11月17日接管了滿洲國郵政，成立「郵總駐長春辦事處」，下轄遼寧、錦州、吉林、牡丹江等郵區。並於1946年2月開始發行東北貼用的郵票。\n",
      "\n",
      "臺灣最早的郵政系統為清治時期的「臺灣郵政總局」。在日治時期，台灣總督府依據日本的郵政體系，重新建立了郵政系統。在第二次世界大戰結束後，中華民國政府接收臺灣，將日治時期的郵政系統收編至中華郵政之下。\n",
      "\n",
      "1888年，臺灣巡撫劉銘傳參考海關軍事傳遞，發布《臺灣郵政條款》十六條，設置「臺灣郵政總局」。\n",
      "\n",
      "1895年，日本開始統治臺灣，日軍設置野戰郵便局，全臺共二十三所。\n",
      "\n",
      "1896年，臺灣施行郵便條例，野戰郵便事務移交「臺灣總督府民政局通信課」接管，郵電合辦。\n",
      "\n",
      "1900年，開辦郵便貯金、匯款業務。\n",
      "1901年，通信課改制為「臺灣總督府通信局」，至1919年再改制為「臺灣總督府遞信局」。\n",
      "\n",
      "1924年，遞信局與鐵道部合併為「臺灣總督府交通局」，下設「遞信部」，至第二次世界大戰結束。\n",
      "\n",
      "1935年，開辦內臺航空郵便（福岡－那霸－臺北）。\n",
      "\n",
      "1936年，開辦島內定期航空郵便，分為西部線（臺北－臺中－高雄）與東部線（臺北－宜蘭－花蓮港）。\n",
      "\n",
      "1945年抗日戰爭結束，中華郵政恢復管理各淪陷區郵政[15][16]，北平、南京及東三省的「偽」郵政總局，暫改為郵政總局駐各地之辦事處[6]:89；1945年11月1日，臺灣省行政長官公署交通處附設「郵電管理委員會」辦理接收臺灣郵政業務[7]:470；11月23日，交通部郵政總局副局長率十人去南京籌備復員事宜，而後總局分批至隔年9月全部自重慶遷回南京[7]:454。\n",
      "\n",
      "1946年5月，「臺灣省郵電管理委員會」裁撤，中央在臺北成立「交通部臺灣郵電管理局」，同時直屬郵政總局與電信總局，維持日本郵電合辦舊制度[7]:470,473。\n",
      "\n",
      "1947年，交通部以1896年3月20日為國家郵政開辦日，將每年3月20日訂為「郵政節」[17]。1948年12月17日，為免南京失守後華南郵務失去中樞，交通部郵政總局設立「西南郵務視導團」以防萬一[7]:467。1949年1月，西南郵務視導團遷至廣州郵局白雲樓辦公，同月底交通部郵政總局遷往上海[7]:468。4月1日，臺灣改行中華民國原有的郵電分辦制度[6]:112，成立「臺灣郵政管理局」、臺灣電信管理局，分別隸屬於交通部郵政總局與交通部電信總局，所屬各級郵政機構同時改組，法規及業務全部納入中華郵政原有系統[7]:470。5月20日，上海發生激戰，總局與外界失去聯繫，時駐廣州交通部的局長霍錫祥將西南郵務視導團改組為郵政總局；8月23日，總局駐穗人員分批遷往臺灣，開始在臺北辦公[7]:468。\n",
      "\n",
      "1965年，交通部郵政總局從臺北縣新店鎮（今新北市新店區）獅頭路遷入臺北郵局郵件大樓辦公。\n",
      "\n",
      "1972年，中華民國因1971年退出聯合國而被迫退出萬國郵政聯盟。\n",
      "\n",
      "1980年，臺灣郵政管理局因應業務發展需要，分割為臺灣北區郵政管理局、臺灣中區郵政管理局、臺灣南區郵政管理局等三個郵政管理單位。\n",
      "\n",
      "2003年1月1日，交通部郵政總局進行公司化（英語：Corporatization），大部分部門改制為中華郵政股份有限公司，原郵政管理局之業務改由中華郵政公司直接管理的責任中心局取代。交通部郵政總局在法律上定義為「郵政機關」，中華郵政公司在法律上則定義為「郵務機構」。\n",
      "\n",
      "2007年2月12日，陳水扁政府執政的行政院主導將該公司改名為「臺灣郵政股份有限公司」，郵票票銘由「中華民國郵票 REPUBLIC OF CHINA」變更為「臺灣 TAIWAN」，但郵政法等相應規範未同時修正，於2008年8月1日復名為「中華郵政股份有限公司」，郵票票銘變更為「中華民國郵票 REPUBLIC OF CHINA（TAIWAN）」。\n",
      "\n",
      "1919-1929年\n",
      "\n",
      "1929-1935年\n",
      "\n",
      "1946年至今\n",
      "\n",
      "中華郵政的營業項目相當多元，其中主要為郵務、金融兩大業務：郵務業務包括郵件遞送與快遞，金融業務則包括郵政儲金、匯兌、簡易人壽保險、房屋貸款、金融商品代銷（英語：Consignment）等。其他服務項目還包括集郵、商品代銷，以及資產營運等經中華民國交通部核可之業務。截至2012年底止，中華郵政在全國各地設有郵局1,322處（不含責任中心局）、委辦機構1,261處（包括郵政代辦所631處、郵票代售處630處）；若將郵局視為一般銀行之分行，是營業據點最多的銀行，遠超過第二名合作金庫商業銀行的288處[18]。除了屏東縣獅子鄉、臺東縣金峰鄉與花蓮縣萬榮鄉外，中華郵政在各鄉鎮市區均設有郵局[19]。\n",
      "\n",
      "雖然中華民國《郵政法》規定信函（法律中定義為具有通訊性質的文件）必須經由郵局寄發，但因電話、網際網路等電子通信方式的普及，加上民間快遞業者競爭，使得中華郵政的本業「郵務業務」大幅萎縮，但因快捷與包裹服務等定價較民間業者相對便宜，因此在臺灣仍擁有一定的市場佔有率。另一方面，中華郵政經營金融服務的時間相當悠久[20]，2012年的營業額甚至達到全公司營業額的80%，遠超過郵務本業的7.93%，壽險資金約新臺幣6,764億元，儲金總額為臺灣各銀行中第一位。\n",
      "\n",
      "2017年12月，與臺灣Pay（台灣行動支付）合作推出郵政HCE手機VISA卡，支援金融雲支付業務。[21]\n",
      "2018年8月，發行感應式VISA金融卡[22]\n",
      "\n",
      "\n",
      "\n",
      "中華郵政公司化之後，原有的郵區制度與郵政管理局被廢止，改以總公司直接管理的「責任中心局」取代，以一縣、市、直轄市設一責任中心局為原則，並由各責任中心局管理轄區內各級郵局。責任中心局除負責執行總公司政策外，也是各自具有獨立性與完整性之業務經營團隊，以促使經營績效得以不斷成長。責任中心局最初有23個，之後因公司組織調整，在2013年3月1日將中壢郵局併入桃園郵局、豐原郵局併入臺中郵局、鳳山郵局併入高雄郵局，然後在2018年1月1日將新營郵局併入臺南郵局，責任中心局總數則縮減至19個。[24][25]\n",
      "\n",
      "\n",
      "臺北北門郵局\n",
      "\n",
      "臺北復興橋郵局\n",
      "\n",
      "臺北延壽郵局\n",
      "\n",
      "汐止郵局\n",
      "\n",
      "臺大醫院郵局\n",
      "\n",
      "基隆港西街郵局\n",
      "\n",
      "基隆愛三路郵局\n",
      "\n",
      "基隆六堵郵局\n",
      "\n",
      "基隆七堵郵局\n",
      "\n",
      "基隆百福郵局\n",
      "\n",
      "臺灣桃園國際機場郵局\n",
      "\n",
      "湖口郵局\n",
      "\n",
      "獅潭郵局\n",
      "\n",
      "臺中郵局\n",
      "\n",
      "大甲廟口郵局\n",
      "\n",
      "白沙屯郵局\n",
      "\n",
      "台北車站郵局\n",
      "\n",
      "嘉義文化路郵局\n",
      "\n",
      "空大郵局\n",
      "\n",
      "陸軍官校郵局\n",
      "\n",
      "阿里山郵局，全臺最高的郵局\n",
      "\n",
      "海軍103敦睦遠航訓練支隊基隆訪問，油彈補給艦武夷（AOE-530）艦上的敦睦遠航訓練支隊臨時郵局\n",
      "\n",
      "台北郵局限時大樓\n",
      "\n",
      "基隆郵局廂型車\n",
      "\n",
      "基隆郵局大貨車\n",
      "\n",
      "一台送修途中的郵政車\n",
      "\n",
      "倫敦版中山像普通郵票（1929年）\n",
      "\n",
      "香港版中山像普通郵票（1931年）\n",
      "\n",
      "紐約版中山像普通郵票（1938年）\n",
      "\n",
      "由於海峽兩岸特殊的政治情勢，臺灣與中國大陸之間雖可通郵，但中華郵政對於中國大陸郵件的投遞上曾採取部分特殊的規定：[26]\n",
      "但在2008年12月15日兩岸通郵之後，此項規定已經被停止使用，唯預印「國際」字樣的信封或地址單，要另外換成「國際（地區）」字樣。\n",
      "\n",
      "2007年2月12日，在當時的執政黨民主進步黨所推動的「台灣正名運動」，中華郵政改名為「臺灣郵政」，但因為受到國民黨等在野政黨的強力反對，所以其設立的法源依據《中華郵政股份有限公司設置條例》一直未能經立法院修改通過，因此在法定名稱方面仍為「中華郵政股份有限公司」[27]。2008年總統大選後，因民進黨敗於國民黨而失去政權，中華郵政董事會又於2008年8月1日決議回復到法定名稱。\n",
      "\n",
      "以下均為UTC+8時區時間\n",
      "\n",
      "\n",
      "\n",
      "中國郵政集團有限公司[2]，簡稱中國郵政，是中華人民共和國一家主要從事郵政寄遞、郵政儲蓄業務的特大型中央企業，是由中華人民共和國財政部代表國務院履行出資人職責的國有獨資公司。\n",
      "\n",
      "中國郵政集團主要經營國內和國際郵件寄遞、報刊和圖書等出版物發行、郵票發行、郵政匯兌、機要通信、郵政金融、郵政速遞、郵政物流、電子商務和各類郵政代理業務[3]。\n",
      "\n",
      "1948年，華北人民政府批准組建華北人民政府交通部郵電總局，主管華北解放區郵政與電信事務。1949年，華北人民政府決定將電信職責劃出，調整組建華北人民政府交通部郵政總局。\n",
      "\n",
      "1949年11月1日，中央人民政府郵電部成立，同年12月郵電部召開全國郵政會議，對原中華民國郵政的事業與機構予以清算接收，組建中國人民郵政；12月27日，中央財政經濟委員會第九次會議決定成立郵政總局。\n",
      "\n",
      "1954年，中華人民共和國國務院成立，國務院設置中華人民共和國郵電部，作為國務院郵電部門。1970年，經中央批准，撤銷郵電部，將郵電管理職責劃入交通部。交通部組建交通部郵政總局，主管全國郵政業務。1973年，國家恢復設立中華人民共和國郵電部。\n",
      "\n",
      "1994年3月1日，國務院批准郵電部機構改革方案，郵政總局由機關行政序列分離，成為專業核算的企業局。1995年10月4日，郵政總局在中華人民共和國國家工商行政管理局註冊了企業法人營業執照，獲得法人資格，企業名稱為「中國郵電郵政總局」，簡稱「中國郵政」。1998年，全國人大批准《國務院機構改革方案》，組建中華人民共和國信息產業部，作為國務院組成部門，撤銷郵電部。組建國家郵政局，作為信息產業部管理的國家局，撤銷中國郵電郵政總局。\n",
      "\n",
      "2005年7月20日，國務院常務會議通過中國郵政「政企分開、郵儲分離、完善機制」的體制改革方案：組建新的國家郵政局，作為政府機構依法監管郵政市場，並協調郵政普遍服務與機要通信等特殊服務的實施；組建中國郵政集團公司，作為國有獨資企業經營各類郵政業務；成立由中國郵政集團公司控股的中國郵政儲蓄銀行，實現金融業務規範化經營；完善郵政普遍服務機制、特殊服務機制、安全保障機制和價格形成機制[4]。2006年8月28日國務院以國函〔2006〕79號批覆[5]，原則同意《中國郵政集團公司組建方案》和《中國郵政集團公司章程》，並指示「中國郵政集團公司」在原郵政總局所屬的經營性資產和部份企事業單位基礎上，依照《中華人民共和國全民所有制工業企業法》組建，不設董事會，出資人職責暫由財政部代表國務院履行，實行總經理負責制，總經理為公司法定代表人。中國郵政集團註冊資金800億元人民幣，但實有國有資本數額待公司正式成立後，財政部進行資產評估和審計驗資後核定。\n",
      "\n",
      "2006年11月27日，原國家郵政局在北京市西城區宣武門西大街131號辦公樓召開最後一屆全體機關幹部大會，宣布留任國家郵政局的具體人選；11月28日，重組後的國家郵政局舉行全體幹部大會。11月29日，中國郵政集團公司在中華人民共和國國家工商行政管理總局註冊登記，註冊號為1000001001822[6]。同年12月31日，中國銀監會批准中國郵政集團公司控股的中國郵政儲蓄銀行開業。2007年1月29日10時30分，國家郵政局和中國郵政集團公司在人民大會堂舉行揭牌儀式。當天稍後，國家郵政局在北京西直門辦公樓前，中國郵政集團公司在北京西便門辦公樓前，分別舉行掛牌儀式。3月20日（農曆二月初二）10時，中國郵政儲蓄銀行在北京總部大樓舉行成立暨掛牌儀式。\n",
      "\n",
      "2015年4月，中國郵政集團公司及所屬中國郵政速遞物流股份有限公司，對管理體制進行調整，由母子公司兩級法人體制改為總分公司一級法人體制[7]。\n",
      "\n",
      "2019年12月28日，中國郵政集團公司改制更名為中國郵政集團有限公司。原中國郵政集團公司全部債權債務、現有的各種專業或特殊資質證照、無形資產等由改制後公司承繼。\n",
      "\n",
      "根據《中華人民共和國郵政法》和國家有關規定，中國郵政集團有限公司為國有獨資企業，依法經營郵政專營業務，承擔郵政普遍服務義務，受政府委託提供郵政特殊服務，對競爭性郵政業務實行商業化運營。中國郵政集團有限公司經營下列業務[8]：\n",
      "\n",
      "根據有關規定，中國郵政集團有限公司內設機構、直屬事業單位為正廳局級。中國郵政集團有限公司設置（控股）下列機構（企業）[9]：\n",
      "\n",
      "劉愛力：董事長、黨組書記\n",
      "張金良：董事、總經理、黨組副書記\n",
      "李丕征：董事、黨組副書記\n",
      "康寧：副總經理、黨組成員\n",
      "張榮林：副總經理、黨組成員\n",
      "郭新雙：副總經理、黨組成員\n",
      "盛遒文：中央紀委國家監委駐中國郵政集團有限公司紀檢監察組組長、黨組成員\n",
      "溫少祺：副總經理、黨組成員\n",
      "郭成林：總會計師、黨組成員[10]\n",
      "目前常見的中華人民共和國普通郵票有「環境保護」、「中國鳥」和「美麗中國」三大系列。除普通郵票外，中國郵政還會不時發行紀念郵票和特種郵票。\n",
      "\n",
      "（以上金額以人民幣為單位）\n",
      "\n",
      "  國務院\n",
      "\n",
      "    中央軍委\n",
      "\n",
      "測繪機構\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = get_url('明信片')\n",
    "get_content(url)\n",
    "linklist = get_keyword(url)\n",
    "for i in linklist:\n",
    "    get_content(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
